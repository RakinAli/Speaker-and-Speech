{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prondict import prondict\n",
    "from path import my_path\n",
    "import os\n",
    "from lab3_tools import *\n",
    "from lab3_proto import *\n",
    "\n",
    "from lab1_tools import *\n",
    "from lab1_proto import *\n",
    "\n",
    "from lab2_tools import *\n",
    "from lab2_proto import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 Forced Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['f', 'k', 'n', 'r', 's', 't', 'v', 'w', 'z', 'ah', 'ao', 'ay', 'eh', 'ey', 'ih', 'iy', 'ow', 'sp', 'th', 'uw', 'sil'])\n",
      "dict_keys(['name', 'startprob', 'transmat', 'means', 'covars'])\n",
      "['ah_0', 'ah_1', 'ah_2', 'ao_0', 'ao_1', 'ao_2', 'ay_0', 'ay_1', 'ay_2', 'eh_0', 'eh_1', 'eh_2', 'ey_0', 'ey_1', 'ey_2', 'f_0', 'f_1', 'f_2', 'ih_0', 'ih_1', 'ih_2', 'iy_0', 'iy_1', 'iy_2', 'k_0', 'k_1', 'k_2', 'n_0', 'n_1', 'n_2', 'ow_0', 'ow_1', 'ow_2', 'r_0', 'r_1', 'r_2', 's_0', 's_1', 's_2', 'sil_0', 'sil_1', 'sil_2', 'sp_0', 't_0', 't_1', 't_2', 'th_0', 'th_1', 'th_2', 'uw_0', 'uw_1', 'uw_2', 'v_0', 'v_1', 'v_2', 'w_0', 'w_1', 'w_2', 'z_0', 'z_1', 'z_2']\n"
     ]
    }
   ],
   "source": [
    " \n",
    "phoneHMMs = np.load('lab2_models_all.npz',allow_pickle=True)['phoneHMMs'].item()\n",
    "phones = sorted(phoneHMMs.keys())\n",
    "nstates = {phone: phoneHMMs[phone]['means'].shape[0] for phone in phones}\n",
    "stateList = [ph + '_' + str(id) for ph in phones for id in range(nstates[ph])]\n",
    "# phoneHMMs contains Hmms for different phones \n",
    "print(phoneHMMs.keys())\n",
    "print(phoneHMMs[\"f\"].keys())\n",
    "print(stateList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['z', '4', '3']\n",
      "['sil', 'z', 'iy', 'r', 'ow', 'sp', 'f', 'ao', 'r', 'sp', 'th', 'r', 'iy', 'sp', 'sil']\n"
     ]
    }
   ],
   "source": [
    "filename = my_path + 'tidigits\\\\disc_4.1.1\\\\tidigits\\\\train\\\\man\\\\nw\\\\z43a.wav'\n",
    "samples, samplingrate = loadAudio(filename)\n",
    "lmfcc = mfcc(samples)\n",
    "\n",
    "#Extract the words from \n",
    "wordTrans = list(path2info(filename)[2])\n",
    "#Extract the phones from the words\n",
    "phoneTrans = words2phones(wordTrans, prondict)\n",
    "\n",
    "print(wordTrans)\n",
    "print(phoneTrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a combined model for the utterance\n",
    "utteranceHMM = concatHMMs(phoneHMMs, phoneTrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sil_0', 'sil_1', 'sil_2', 'z_0', 'z_1', 'z_2', 'iy_0', 'iy_1', 'iy_2', 'r_0', 'r_1', 'r_2', 'ow_0', 'ow_1', 'ow_2', 'sp_0', 'f_0', 'f_1', 'f_2', 'ao_0', 'ao_1', 'ao_2', 'r_0', 'r_1', 'r_2', 'sp_0', 'th_0', 'th_1', 'th_2', 'r_0', 'r_1', 'r_2', 'iy_0', 'iy_1', 'iy_2', 'sp_0', 'sil_0', 'sil_1', 'sil_2']\n"
     ]
    }
   ],
   "source": [
    "#map the states in utteranceHMM into the unique state names in stateList\n",
    "stateTrans = [phone + '_' + str(stateid) for phone in phoneTrans for stateid in range(nstates[phone])]\n",
    "print(stateTrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cmp23\\Skrivbord\\DT2119-Speech-and-Speaker-Recognition_labs\\Lab 3\\Hasan\\lab3_proto.py:52: RuntimeWarning: divide by zero encountered in log\n",
      "  _, viterb_path = viterbi(obsloglik, np.log(utteranceHMM['startprob']), np.log(utteranceHMM['transmat'][:-1, :-1]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0 0.02 sil_0\\n0.02 0.20000000000000004 sil_1\\n0.20000000000000004 0.21000000000000005 sil_2\\n0.21000000000000005 0.25000000000000006 z_0\\n0.25000000000000006 0.26000000000000006 z_1\\n0.26000000000000006 0.37000000000000016 z_2\\n0.37000000000000016 0.45000000000000023 iy_0\\n0.45000000000000023 0.46000000000000024 iy_1\\n0.46000000000000024 0.47000000000000025 iy_2\\n0.47000000000000025 0.5700000000000003 r_0\\n0.5700000000000003 0.5800000000000003 r_1\\n0.5800000000000003 0.5900000000000003 r_2\\n0.5900000000000003 0.6000000000000003 ow_0\\n0.6000000000000003 0.6100000000000003 ow_1\\n0.6100000000000003 0.7000000000000004 ow_2\\n0.7000000000000004 0.7100000000000004 f_0\\n0.7100000000000004 0.8200000000000005 f_1\\n0.8200000000000005 0.8300000000000005 f_2\\n0.8300000000000005 0.8400000000000005 ao_0\\n0.8400000000000005 0.9800000000000006 ao_1\\n0.9800000000000006 1.0900000000000007 ao_2\\n1.0900000000000007 1.1200000000000008 r_0\\n1.1200000000000008 1.1300000000000008 r_1\\n1.1300000000000008 1.1400000000000008 r_2\\n1.1400000000000008 1.2400000000000009 th_0\\n1.2400000000000009 1.270000000000001 th_1\\n1.270000000000001 1.280000000000001 th_2\\n1.280000000000001 1.370000000000001 r_0\\n1.370000000000001 1.380000000000001 r_1\\n1.380000000000001 1.390000000000001 r_2\\n1.390000000000001 1.490000000000001 iy_0\\n1.490000000000001 1.5100000000000011 iy_1\\n1.5100000000000011 1.5900000000000012 iy_2\\n1.5900000000000012 1.7800000000000014 sil_0\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viterbiStateTrans = forcedAlignment(lmfcc,phoneHMMs,phoneTrans,stateTrans)\n",
    "frames2trans(viterbiStateTrans, outfilename='z43a.lab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntraindata = []\\nfor root, dirs, files in os.walk(my_path +  'tidigits\\\\disc_4.1.1\\\\tidigits\\\\train'):\\n for file in files:\\n  if file.endswith('.wav'):\\n    filename = os.path.join(root, file)\\n    samples, samplingrate = loadAudio(filename)\\n    lmfcc_uttarnce = mfcc(samples)\\n    mspec_uttarnce = mspec(samples)\\n    \\n\\n    wordTrans = list(path2info(filename)[2])\\n    \\n    phoneTrans = words2phones(wordTrans, prondict)\\n    stateTrans = [phone + '_' + str(stateid) for phone in phoneTrans for stateid in range(nstates[phone])]\\n    viterbiStateTrans = forcedAlignment(lmfcc_uttarnce,phoneHMMs,phoneTrans,stateTrans)\\n    \\n    targets = []\\n    for state in viterbiStateTrans:\\n      targets.append(stateList.index(state))\\n  \\n    traindata.append({'filename': filename, 'lmfcc': lmfcc_uttarnce,'mspec': mspec_uttarnce, 'targets': targets})\\n\\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "traindata = []\n",
    "for root, dirs, files in os.walk(my_path +  'tidigits\\\\disc_4.1.1\\\\tidigits\\\\train'):\n",
    " for file in files:\n",
    "  if file.endswith('.wav'):\n",
    "    filename = os.path.join(root, file)\n",
    "    samples, samplingrate = loadAudio(filename)\n",
    "    lmfcc_uttarnce = mfcc(samples)\n",
    "    mspec_uttarnce = mspec(samples)\n",
    "    \n",
    "\n",
    "    wordTrans = list(path2info(filename)[2])\n",
    "    \n",
    "    phoneTrans = words2phones(wordTrans, prondict)\n",
    "    stateTrans = [phone + '_' + str(stateid) for phone in phoneTrans for stateid in range(nstates[phone])]\n",
    "    viterbiStateTrans = forcedAlignment(lmfcc_uttarnce,phoneHMMs,phoneTrans,stateTrans)\n",
    "    \n",
    "    targets = []\n",
    "    for state in viterbiStateTrans:\n",
    "      targets.append(stateList.index(state))\n",
    "  \n",
    "    traindata.append({'filename': filename, 'lmfcc': lmfcc_uttarnce,'mspec': mspec_uttarnce, 'targets': targets})\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savez('traindata.npz', traindata=traindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntestdata = []\\nfor root, dirs, files in os.walk(my_path +  'tidigits\\\\disc_4.2.1\\\\tidigits\\\\test'):\\n for file in files:  \\n  if file.endswith('.wav'):\\n    filename = os.path.join(root, file)\\n    samples, samplingrate = loadAudio(filename)\\n    lmfcc_uttarnce = mfcc(samples)\\n    mspec_uttarnce = mspec(samples)\\n    \\n\\n    wordTrans = list(path2info(filename)[2])\\n    \\n    phoneTrans = words2phones(wordTrans, prondict)\\n    stateTrans = [phone + '_' + str(stateid) for phone in phoneTrans for stateid in range(nstates[phone])]\\n    viterbiStateTrans = forcedAlignment(lmfcc_uttarnce,phoneHMMs,phoneTrans,stateTrans)\\n    \\n\\n    targets = []\\n    for state in viterbiStateTrans:\\n      targets.append(stateList.index(state))\\n  \\n    testdata.append({'filename': filename, 'lmfcc': lmfcc_uttarnce,'mspec': mspec_uttarnce, 'targets': targets})\\n\\n\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "testdata = []\n",
    "for root, dirs, files in os.walk(my_path +  'tidigits\\\\disc_4.2.1\\\\tidigits\\\\test'):\n",
    " for file in files:  \n",
    "  if file.endswith('.wav'):\n",
    "    filename = os.path.join(root, file)\n",
    "    samples, samplingrate = loadAudio(filename)\n",
    "    lmfcc_uttarnce = mfcc(samples)\n",
    "    mspec_uttarnce = mspec(samples)\n",
    "    \n",
    "\n",
    "    wordTrans = list(path2info(filename)[2])\n",
    "    \n",
    "    phoneTrans = words2phones(wordTrans, prondict)\n",
    "    stateTrans = [phone + '_' + str(stateid) for phone in phoneTrans for stateid in range(nstates[phone])]\n",
    "    viterbiStateTrans = forcedAlignment(lmfcc_uttarnce,phoneHMMs,phoneTrans,stateTrans)\n",
    "    \n",
    "\n",
    "    targets = []\n",
    "    for state in viterbiStateTrans:\n",
    "      targets.append(stateList.index(state))\n",
    "  \n",
    "    testdata.append({'filename': filename, 'lmfcc': lmfcc_uttarnce,'mspec': mspec_uttarnce, 'targets': targets})\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savez('testdata.npz', testdata=testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = np.load('traindata.npz',allow_pickle=True)['traindata']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data: 1507392\n",
      "The percentage of validation_data: 10.0\n",
      "The percentage of training_data:: 90.0\n",
      "\n",
      "The persenatge of men in validation: 50.0\n",
      "The persenatge of women in validation: 50.0\n",
      "\n",
      "The percentage of men in the training_data: 48.0\n",
      "The percentage of women in the training_data: 52.0\n"
     ]
    }
   ],
   "source": [
    "data_train = []\n",
    "data_validation =[]\n",
    "\n",
    "#6 men and 6 women to include in the validation set\n",
    "#It will be 10 % of the entire data\n",
    "id_validation = ['ae','aj','al','aw','bd','cb','ac','ag', 'ai', 'an','bh','bi']\n",
    "\n",
    "counter_validation = 0\n",
    "counter_train = 0\n",
    "counter_all = 0\n",
    "\n",
    "validation_c_man = 0\n",
    "validation_c_women = 0\n",
    "\n",
    "train_c_man = 0\n",
    "train_c_women = 0\n",
    "\n",
    "for i in range((len(traindata))):\n",
    "  file = traindata[i]['filename']\n",
    "  id = path2info(file)[1]\n",
    "  gender = path2info(file)[0]\n",
    "\n",
    "  N = traindata[i]['lmfcc'].shape[0]\n",
    "  counter_all += N\n",
    "\n",
    "  \n",
    "  if id in id_validation:\n",
    "   counter_validation  += N\n",
    "   data_validation.append(traindata[i])\n",
    "   if gender=='man': \n",
    "    validation_c_man += N\n",
    "   if gender=='woman':\n",
    "    validation_c_women +=N\n",
    "        \n",
    "  else:\n",
    "   data_train.append(traindata[i])  \n",
    "   counter_train +=N \n",
    "   if gender=='man': \n",
    "    train_c_man += N\n",
    "   if gender=='woman':\n",
    "    train_c_women +=N   \n",
    "   \n",
    "\n",
    "print(\"Number of data: \" + str(counter_all))\n",
    "\n",
    "print(\"The percentage of validation_data: \" + str(100*np.round(counter_validation/counter_all,2)))\n",
    "print(\"The percentage of training_data:: \" + str(100*np.round(counter_train/counter_all,2)))\n",
    "print()\n",
    "print(\"The persenatge of men in validation: \"   + str(100*np.round(validation_c_man/counter_validation,2)))\n",
    "print(\"The persenatge of women in validation: \" + str(100*np.round(validation_c_women/counter_validation,2)))\n",
    "print()\n",
    "print(\"The percentage of men in the training_data: \" + str(100*np.round(train_c_man/counter_train,2)))\n",
    "print(\"The percentage of women in the training_data: \" + str(100*np.round(train_c_women/counter_train,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indicies(index , last_index):\n",
    "  left_index = index\n",
    "  right_index = index\n",
    "  t = [index]\n",
    "  for i in range(3):\n",
    "    \n",
    "    left_index -=1\n",
    "    t.insert(0,left_index)\n",
    "\n",
    "    if(right_index==last_index):\n",
    "       right_index =0\n",
    "       t.append(right_index)\n",
    "    else:\n",
    "        right_index +=1 \n",
    "        t.append(right_index)\n",
    "\n",
    "  for i in range(len(t)):\n",
    "    if(t[i]<0):\n",
    "      t[i] = -1 * t[i]\n",
    "\n",
    "  return t    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def Dynamic_Features(x):\n",
    "  \n",
    "  g = np.zeros((x.shape[0], 7* x.shape[1]))\n",
    "  \n",
    "\n",
    "  for i in range(x.shape[0]):\n",
    "     list = get_indicies(i,x.shape[0]-1)\n",
    "     temp = x[list ,:]\n",
    "     g[i] = temp.flatten()\n",
    "\n",
    "  return np.array(g)   \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
